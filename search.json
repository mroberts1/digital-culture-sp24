[
  {
    "objectID": "observable.html",
    "href": "observable.html",
    "title": "  ",
    "section": "",
    "text": "d3 = require(\"d3@7\")\n\n\n\n\n\n\n\nP5 = require(\"p5\")\n\nfunction* createSketch(sketch) {\n  const element = DOM.element('div');\n  yield element;\n  const instance = new P5(sketch, element, true);\n  try {\n    while (true) {\n      yield element;\n    }\n  } finally {\n    instance.remove();\n  }\n}\n\ncreateSketch(s =&gt; {\n\n  s.setup = function() {\n    s.createCanvas(500, 500, s.WEBGL);\n    s.noStroke();\n  }\n\n  s.draw = function() {\n\n    s.background(0);\n\n    let locX = s.mouseX - s.height / 2;\n    let locY = s.mouseY - s.width / 2;\n\n    s.ambientLight(60, 60, 60);\n    s.pointLight(190, 80, 190, locX, locY, 100);\n    s.pointLight(80, 80, 190, 0, 0, 100);\n\n    s.specularMaterial(255);\n    s.rotateX(s.frameCount * 0.01);\n    s.rotateY(s.frameCount * 0.01);\n    s.torus(150, 80, 64, 64);\n  }\n\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncreateSketch(s =&gt; {\n\n    s.setup = function() {\n      s.createCanvas(500, 500);\n      s.background(0);\n      s.noStroke();\n    };\n\n    s.draw = function() {\n      s.translate(\n        100 * s.cos(s.millis() * .001 * s.PI),\n        100 * s.sin(s.millis() * .001 * s.PI),\n      );\n      if (s.random(0, 1) &lt; .1) {\n        s.fill(s.random(0, 255));\n      }\n      s.circle(250, 250, 100);\n    };\n\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\ncreateSketch(s =&gt; {\n\n    s.setup = function() {\n      s.createCanvas(746, 300);\n      s.textFont('Avenir');\n      s.textStyle(s.BOLD);\n      s.textAlign(s.CENTER, s.CENTER)\n    };\n\n    s.draw = function() {\n      s.translate(\n        s.millis() * (-0.1) % (s.width + 1000),\n        s.height / 2\n      );\n      s.background('#62259D');\n      s.fill('#fff').textSize(50);\n      s.text('VM303 Studies in Digital Media & Culture', s.width + 500, 0);\n    };\n\n  }\n)\n\n\n\n\n\n\n\n\ncreateSketch(s =&gt; {\n\n  let n = 100;\n  let dot;\n  let dotList = [];\n  let palette = [\n    s.color(\"#6B1B00\"),\n    s.color(\"#AE8B70\"),\n    s.color(\"#F9FEFB\"),\n    s.color(\"#56382D\")\n  ];\n\n  s.setup = function() {\n    s.createCanvas(746, 746);\n    for(let i = 0; i &lt; n; i++) {\n      let angle = s.random(0, s.TWO_PI);\n      let radius = s.width * s.random(.12, .33);\n      dotList.push(dot = new Dot(\n        s,\n        s.width/2 + s.cos(angle) * radius,\n        s.height/2 + s.sin(angle) * radius,\n        s.random(palette),\n        s.random(1, 5)\n      ));\n    }\n  };\n\n  s.draw = function() {\n    dotList.map(dot =&gt; {\n      dot.on();\n      dot.move();\n      dot.bounce(s.width * .35, true);\n      dot.bounce(s.width * .1, false);\n    });\n  };\n})\n\n\n\n\n\n\n\nclass Dot {\n  constructor(sketch, x, y, colour, size) {\n    this.s = sketch;\n    this.x = x | 0;\n    this.y = y | 0;\n    this.colour = colour;\n    this.size = size;\n    this.velX = this.s.random(-2, 2);\n    this.velY = this.s.random(-2, 2);\n  }\n\n  on() {\n    this.s.noStroke();\n    this.s.fill(this.colour);\n    this.s.circle(this.x, this.y, this.size);\n  }\n\n  move() {\n    this.x += this.velX;\n    this.y += this.velY;\n  }\n\n  bounce(radius, inside) {\n    let x = this.x - this.s.width/2;\n    let y = this.y - this.s.height/2;\n    if (\n      inside && x*x + y*y &gt; radius * radius ||\n      !inside && x*x + y*y &lt; radius * radius\n    ) {\n\n      // https://math.stackexchange.com/a/611836\n      let nx = x / this.s.sqrt(x*x + y*y);\n      let ny = y / this.s.sqrt(x*x + y*y);\n      let vx = this.velX;\n      let vy = this.velY;\n      this.velX = (ny*ny - nx*nx)*vx - 2*nx*ny*vy;\n      this.velY = (nx*nx - ny*ny)*vy - 2*nx*ny*vx;\n\n    }\n  }\n\n}\n\n\n\n\n\n\n\n\n\n\ncreateSketch(s =&gt; {\n    s.setup = function() {\n      s.createCanvas(500, 500);\n      s.background(\"black\");\n      s.fill(\"red\").circle(250, 250, 100);\n      s.fill(\"black\").circle(250, 250, 30);\n    };\n  }\n)"
  },
  {
    "objectID": "w9-aiff.html",
    "href": "w9-aiff.html",
    "title": "W9: AI Film Festival 2023",
    "section": "",
    "text": "Generation - Riccardo Fusetti\n\n\nCheckpoint - Áron Filkey and Joss Fong\n\n\nPLSTC - Laen Sanches\n\n\nLandscape - Kyle Goodrich\n\n\nA$AP Rocky - Shittin Me - Dan Streit and Cole Kush\n\n\nExpanded Childhood - Sam Lawton"
  },
  {
    "objectID": "webgl-sobel.html",
    "href": "webgl-sobel.html",
    "title": "  ",
    "section": "",
    "text": "viewof gl = {\n  const canvas = DOM.canvas(width, height);\n  canvas.value = canvas.getContext(\"webgl\");\n  return canvas;\n}\n\n\n\n\n\n\n\ndraw = {\n  gl.useProgram(program);\n  gl.enableVertexAttribArray(a_vertex);\n  gl.vertexAttribPointer(a_vertex, 2, gl.FLOAT, false, 0, 0);\n  gl.uniform1f(u_size, Math.max(viewof gl.width, viewof gl.height));\n  while (true) {\n    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, video);\n    gl.drawArrays(gl.TRIANGLE_FAN, 0, 4);\n    yield;\n  }\n}\n\n\n\n\n\n\n\nfragmentShader = {\n  const shader = gl.createShader(gl.FRAGMENT_SHADER);\n  gl.shaderSource(shader, `\nprecision highp float;\n\nuniform sampler2D u_image;\nuniform float u_size;\n\nvoid main() {\n  float x = gl_FragCoord.x / u_size;\n  float y = 1.0 - gl_FragCoord.y / u_size;\n  float px = 1.0 / u_size;\n  vec3 a0 = texture2D(u_image, vec2(x - px, y + px)).xyz;\n  vec3 a1 = texture2D(u_image, vec2(x, y + px)).xyz;\n  vec3 a2 = texture2D(u_image, vec2(x + px, y + px)).xyz;\n  vec3 a3 = texture2D(u_image, vec2(x - px, y)).xyz;\n  vec3 a5 = texture2D(u_image, vec2(x + px, y)).xyz;\n  vec3 a6 = texture2D(u_image, vec2(x - px, y - px)).xyz;\n  vec3 a7 = texture2D(u_image, vec2(x, y - px)).xyz;\n  vec3 a8 = texture2D(u_image, vec2(x + px, y - px)).xyz;\n  vec3 gx = -a0 + a2 - 2.0 * a3 + 2.0 * a5 - a6 + a8;\n  vec3 gy = -a0 - 2.0 * a1 - a2 + a6 + 2.0 * a7 + a8;\n  gl_FragColor = vec4(sqrt(gx * gx + gy * gy), 1.0);\n}\n`);\n  gl.compileShader(shader);\n  if (gl.getShaderParameter(shader, gl.COMPILE_STATUS)) return shader;\n  throw new Error(gl.getShaderInfoLog(shader));\n}\n\n\n\n\n\n\n\nvertexShader = {\n  const shader = gl.createShader(gl.VERTEX_SHADER);\n  gl.shaderSource(shader, `\nattribute vec2 a_vertex;\n\nvoid main(void) {\n  gl_Position = vec4(a_vertex, 0.0, 1.0);\n}\n`);\n  gl.compileShader(shader);\n  if (gl.getShaderParameter(shader, gl.COMPILE_STATUS)) return shader;\n  throw new Error(gl.getShaderInfoLog(shader));\n}\n\n\n\n\n\n\n\nvertexBuffer = {\n  const buffer = gl.createBuffer();\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n  gl.bufferData(gl.ARRAY_BUFFER, Float32Array.of(-1, -1, +1, -1, +1, +1, -1, +1), gl.STATIC_DRAW);\n  return buffer;\n}\n\n\n\n\n\n\n\nvideo = {\n  const video = document.createElement(\"div\").appendChild(html`&lt;video autoplay playsinline&gt;`);\n  const stream = await navigator.mediaDevices.getUserMedia({\n    video: {width: {ideal: size}, height: {ideal: size}},\n    audio: false\n  });\n  yield video;\n  video.srcObject = stream;\n  video.play();\n  invalidation.then(() =&gt; stream.getTracks().forEach(t =&gt; t.stop()));\n}\n\n\n\n\n\n\n\ntexture = {\n  const texture = gl.createTexture();\n  gl.bindTexture(gl.TEXTURE_2D, texture);\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);\n  return texture;\n}\n\n\n\n\n\n\n\nprogram = {\n  const program = gl.createProgram();\n  gl.attachShader(program, vertexShader);\n  gl.attachShader(program, fragmentShader);\n  gl.linkProgram(program);\n  if (gl.getProgramParameter(program, gl.LINK_STATUS)) return program;\n  throw new Error(gl.getProgramInfoLog(program));\n}\n\n\n\n\n\n\n\nu_size = gl.getUniformLocation(program, \"u_size\")\n\n\n\n\n\n\n\na_vertex = gl.getAttribLocation(program, \"a_vertex\")\n\n\n\n\n\n\n\nsize = 512\n\n\n\n\n\n\n\nheight = width"
  },
  {
    "objectID": "vanilla-boids.html",
    "href": "vanilla-boids.html",
    "title": "  ",
    "section": "",
    "text": "{\n  let startTime = (new Date()).getTime(), seconds = 0, secondsRounded = 0, ticks = 0, speeds = [];\n\n  const ctx = DOM.context2d(myBoids.width(), myBoids.height());\n\n  let holding = false;\n  ctx.canvas.addEventListener(\"mousedown\", e =&gt; { holding = true; addBoidOnEvent(e); });\n  ctx.canvas.addEventListener(\"mouseup\", e =&gt; { holding = false });\n  ctx.canvas.addEventListener(\"mousemove\", e =&gt; { if (holding) addBoidOnEvent(e); });\n\n  while (true && myBoids.flock.length){\n    myBoids.tick();\n    ctx.clearRect(0, 0, myBoids.width(), myBoids.height());\n\n    myBoids.each(boid =&gt; {\n      const a = vecmath.trans(boid.pos, boid.ang - Math.PI * .5, 3),\n            b = vecmath.trans(boid.pos, boid.ang, 9),\n            c = vecmath.trans(boid.pos, boid.ang + Math.PI * .5, 3);\n\n      ctx.beginPath();\n\n      ctx.moveTo(...a);\n      ctx.lineTo(...b);\n      ctx.lineTo(...c);\n      ctx.lineTo(...a);\n\n      const color = d3.interpolateRdPu(.6 * myBoids.maxSpeed() / boid.speed);\n      ctx.strokeStyle = color;\n      ctx.fillStyle = d3.color(color).brighter(2);\n\n      ctx.fill();\n      ctx.stroke();\n    });\n\n    seconds = ((new Date()).getTime() - startTime) / 1e3;\n    ticks++;\n    document.querySelector(\".ticker\").innerHTML = `${myBoids.flock.length} boids at ${d3.mean(speeds)} frames per second`;\n\n    if (Math.round(seconds) !== secondsRounded){\n      speeds.push(ticks);\n      if (speeds.length &gt; 2) speeds.shift();\n      secondsRounded = Math.round(seconds);\n      ticks = 0;\n    }\n\n    yield ctx.canvas;\n  }\n}\n\n\n\n\n\n\n\n{\n  const el = DOM.element(\"div\");\n  el.classList.add(\"ticker\");\n  return el;\n}\n\n\n\n\n\n\n\nviewof useTree = checkbox({\n  options: [{ value: \"true\", label: \"Use RBush\" }],\n  value: \"true\",\n  description: \"Use a quadtree to improve performance\"\n})\n\n\n\n\n\n\n\nviewof alignment = slider({\n  title: \"Alignment\",\n  value: 1,\n  min: 0,\n  max: 1,\n  step: .1,\n  description: \"Steer towards the average heading of local flockmates\"\n});\n\n\n\n\n\n\n\nviewof cohesion = slider({\n  title: \"Cohesion\",\n  value: 1,\n  min: 0,\n  max: 1,\n  step: .1,\n  description: \"Steer towards the average position of local flockmates\"\n});\n\n\n\n\n\n\n\nviewof separation = slider({\n  title: \"Separation\",\n  value: 1,\n  min: 0,\n  max: 1,\n  step: .1,\n  description: \"Steer to avoid crowding local flockmates\"\n});\n\n\n\n\n\n\n\nviewof perception = slider({\n  title: \"Perception\",\n  value: 20,\n  min: 1,\n  max: 60,\n  step: 1,\n  description: \"Maximum distance of other boids to consider\"\n});\n\n\n\n\n\n\n\ntoc({selector: \"h2\"})\n\n\n\n\n\n\n\nmd`## API Reference\n\nTo use the Boids class in your own notebook ([example](https://observablehq.com/@harrystevens/minimalist-boids?collection=@harrystevens/boids)):\n\n~~~js\nimport { Boids } from \"@harrystevens/vanilla-boids\"\n~~~\n\n&lt;b&gt;Boids&lt;/b&gt;\n\nCreates a new simulation, setting &lt;i&gt;alignment&lt;/i&gt;, &lt;i&gt;cohesion&lt;/i&gt;, and &lt;i&gt;separation&lt;/i&gt; to 1, &lt;i&gt;perception&lt;/i&gt; to 20, &lt;i&gt;width&lt;/i&gt; to the notebook’s width, and &lt;i&gt;height&lt;/i&gt; to 500.\n\n~~~js\nconst myBoids = new Boids();\n~~~\n\nboids.&lt;b&gt;add&lt;/b&gt;([&lt;i&gt;options&lt;/i&gt;])\n\nAdds a boid to the simulation with a random position and angle, and with a speed of 1, and returns the simulation. You can pass an &lt;i&gt;options&lt;/i&gt; object with the following properties:\n\n| property | type   | description                                                                                                                                                 |\n|----------|--------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| pos      | Array  | Starting position for the boid, specified as an array of two numbers, where the first number is the x-coordinate and the second number is the y-coordinate. |\n| ang      | Number | Starting angle for the boid, specified as a number in radians.                                                                                                |\n| speed    | Number | Starting speed for the boid, specified as a number.                                                                                                         |\n&lt;br /&gt;\n\nboids.&lt;b&gt;each&lt;/b&gt;(&lt;i&gt;accessor&lt;/i&gt;)\n\nLoops through the flock of boids, invoking an &lt;i&gt;accessor&lt;/i&gt; function on each boid one at a time. The accessor is passed three arguments: the current boid, the current index, and the entire flock.\n\nboids.&lt;b&gt;tick&lt;/b&gt;()\n\nAdvances the simulation one tick and returns the simulation.\n\nboids.&lt;b&gt;alignment&lt;/b&gt;([&lt;i&gt;alignment&lt;/i&gt;])\n\nIf &lt;i&gt;alignment&lt;/i&gt; is specified, sets the alignment force to a number and returns the simulation. Alignment forces the boids to steer towards the average heading of local flockmates. If &lt;i&gt;alignment&lt;/i&gt; is not specified, returns the current alignment force, which defaults to 1.\n\nboids.&lt;b&gt;cohesion&lt;/b&gt;([&lt;i&gt;cohesion&lt;/i&gt;])\n\nIf &lt;i&gt;cohesion&lt;/i&gt; is specified, sets the cohesion force to a number and returns the simulation. Cohesion forces the boids to steer towards the average position of local flockmates. If &lt;i&gt;cohesion&lt;/i&gt; is not specified, returns the current cohesion force, which defaults to 1.\n\nboids.&lt;b&gt;separation&lt;/b&gt;([&lt;i&gt;separation&lt;/i&gt;])\n\nIf &lt;i&gt;separation&lt;/i&gt; is specified, sets the separation force to a number and returns the simulation. Separation forces the boids to steer to avoid crowding local flockmates. If &lt;i&gt;separation&lt;/i&gt; is not specified, returns the current separation force, which defaults to 1.\n\nboids.&lt;b&gt;perception&lt;/b&gt;([&lt;i&gt;perception&lt;/i&gt;])\n\nIf &lt;i&gt;perception&lt;/i&gt; is specified, sets the perception radius of the boids to a number of pixels and returns the simulation. The boids’ movement will be affected only by those other boids whose positions fall within the perception radius. If &lt;i&gt;perception&lt;/i&gt; is not specified, returns the current perception radius, which defaults to 20.\n\nboids.&lt;b&gt;width&lt;/b&gt;([&lt;i&gt;width&lt;/i&gt;])\n\nIf &lt;i&gt;width&lt;/i&gt; is specified, sets the width of the simulation to a number of pixels and returns the simulation. If &lt;i&gt;width&lt;/i&gt; is not specified, returns the current width, which defaults to the notebook’s width.\n\nboids.&lt;b&gt;height&lt;/b&gt;([&lt;i&gt;height&lt;/i&gt;])\n\nIf &lt;i&gt;height&lt;/i&gt; is specified, sets the height of the simulation to a number of pixels and returns the simulation. If &lt;i&gt;height&lt;/i&gt; is not specified, returns the current height, which defaults to 500.\n\nboids.&lt;b&gt;maxSpeed&lt;/b&gt;([&lt;i&gt;speed&lt;/i&gt;])\n\nIf &lt;i&gt;speed&lt;/i&gt; is specified, sets the maximum speed of the boids to a number of pixels per tick and returns the simulation. If &lt;i&gt;speed&lt;/i&gt; is not specified, returns the current maximum speed, which defaults to 4.\n`\n\n\n\n\n\n\n\nmd`## Code`\n\n\n\n\n\n\n\nmyBoids = {\n  const sim = new Boids();\n\n  // Add 500 boids\n  for (let i = 0; i &lt; 500; i++) {\n    sim.add();\n  }\n\n  return sim;\n}\n\n\n\n\n\n\n\nmyBoids\n  .alignment(alignment)\n  .cohesion(cohesion)\n  .separation(separation)\n  .perception(perception)\n  .quadtree(!!useTree);\n\n\n\n\n\n\n\nfunction addBoidOnEvent(e){\n  myBoids.add({\n    pos: [e.offsetX, e.offsetY]\n  });\n}\n\n\n\n\n\n\n\nclass Boids {\n  constructor(){\n    this._width = width;\n    this._height = height;\n    this._perception = 20;\n    this._alignment = 1;\n    this._cohesion = 1;\n    this._separation = 1;\n    this._maxSpeed = 4;\n    this._quadtree = true;\n    this.maxForce = 0.2;\n    this.flock = [];\n    this.tree = new BoidBush();\n  }\n\n  alignment(n){\n    if (isFinite(n)){\n      this._alignment = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._alignment = n;\n      }\n      return this;\n    }\n    else {\n      return this._alignment;\n    }\n  }\n\n  cohesion(n){\n    if (isFinite(n)){\n      this._cohesion = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._cohesion = n;\n      }\n      return this;\n    }\n    else {\n      return this._cohesion;\n    }\n  }\n\n  perception(n){\n    if (isFinite(n)){\n      this._perception = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._perception = n;\n      }\n      return this;\n    }\n    else {\n      return this._perception;\n    }\n  }\n\n  separation(n){\n    if (isFinite(n)){\n      this._separation = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._separation = n;\n      }\n      return this;\n    }\n    else {\n      return this._separation;\n    }\n  }\n\n  width(n){\n    if (isFinite(n)){\n      this._width = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._width = n;\n      }\n      return this;\n    }\n    else {\n      return this._width;\n    }\n  }\n\n  height(n){\n    if (isFinite(n)){\n      this._height = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._height = n;\n      }\n      return this;\n    }\n    else {\n      return this._height;\n    }\n  }\n\n  quadtree(bool){\n    if (arguments.length) {\n      this._quadtree = bool;\n      if (this._quadtree && !this.tree) this.tree = new BoidBush();\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._quadtree = bool;\n        this.flock[i].tree = this.tree;\n      }\n      return this;\n    }\n    else {\n      return this._quadtree;\n    }\n  }\n\n  maxSpeed(n){\n    if (isFinite(n)){\n      this._maxSpeed = n;\n      for (let i = 0, l = this.flock.length; i &lt; l; i++){\n        this.flock[i]._maxSpeed = n;\n      }\n      return this;\n    }\n    else {\n      return this._maxSpeed;\n    }\n  }\n\n  add(opts){\n    this.flock.push(new Boid(this, opts));\n    return this;\n  }\n\n  each(fn){\n    for (let i = 0, l = this.flock.length; i &lt; l; i++){\n      fn(this.flock[i], i, this.flock);\n    }\n    return this;\n  }\n\n  tick(){\n    if (this._quadtree) {\n      this.tree.clear();\n      this.tree.load(this.flock);\n    }\n\n    this.each(boid =&gt; boid.update());\n\n    return this;\n  }\n}\n\n\n\n\n\n\n\nclass Boid {\n  constructor(Boids, opts){\n    Object.assign(this, Boids);\n    Object.assign(this, opts);\n\n    // Angle, position, and speed can be assigned by the user.\n    this.ang = this.ang || 2 * Math.random() * Math.PI;\n    this.pos = this.pos || [\n      Math.random() * this._width,\n      Math.random() * this._height\n    ];\n    this.speed = this.speed || 1;\n\n    const obj = {\n      pos: this.pos,\n      ang: this.ang,\n      speed: this.speed,\n      vel: vecmath.sub(\n        vecmath.trans(this.pos, this.ang, this.speed),\n        this.pos\n      ),\n      acc: [0, 0],\n      id: this.flock.length\n    };\n\n    Object.assign(this, obj);\n  }\n\n  update(){\n    const prev = { ...this };\n\n    let alignment = [0, 0],\n        cohesion = [0, 0],\n        separation = [0, 0],\n        n = 0,\n        candidates = this.flock;\n\n    if (this._quadtree){\n      candidates = this.tree.search({\n        minX: this.pos[0] - this._perception,\n        minY: this.pos[1] - this._perception,\n        maxX: this.pos[0] + this._perception,\n        maxY: this.pos[1] + this._perception,\n      });\n    }\n\n    for (let i = 0, l = candidates.length; i &lt; l; i ++){\n      const that = candidates[i],\n            dist = vecmath.dist(this.pos, that.pos);\n\n      if (this.id !== that.id && dist &lt; this._perception){\n        alignment = vecmath.add(alignment, that.vel);\n        cohesion = vecmath.add(cohesion, that.pos);\n        const diff = vecmath.div(\n          vecmath.sub(this.pos, that.pos),\n          Math.max(dist, epsilon)\n        );\n        separation = vecmath.add(separation, diff);\n        n++;\n      }\n    }\n\n    if (n &gt; 0){\n      alignment = vecmath.div(alignment, n);\n      alignment = vecmath.setMag(alignment, this._maxSpeed);\n      alignment = vecmath.sub(alignment, this.vel);\n      alignment = vecmath.limit(alignment, this.maxForce);\n\n      cohesion = vecmath.div(cohesion, n);\n      cohesion = vecmath.sub(cohesion, this.pos);\n      cohesion = vecmath.setMag(cohesion, this._maxSpeed);\n      cohesion = vecmath.sub(cohesion, this.vel);\n      cohesion = vecmath.limit(cohesion, this.maxForce);\n\n      separation = vecmath.div(separation, n);\n      separation = vecmath.setMag(separation, this._maxSpeed);\n      separation = vecmath.sub(separation, this.vel);\n      separation = vecmath.limit(separation, this.maxForce);\n    }\n\n    alignment = vecmath.mult(alignment, this._alignment);\n    cohesion = vecmath.mult(cohesion, this._cohesion);\n    separation = vecmath.mult(separation, this._separation);\n\n    this.acc = vecmath.add(this.acc, alignment);\n    this.acc = vecmath.add(this.acc, cohesion);\n    this.acc = vecmath.add(this.acc, separation);\n\n    this.pos = vecmath.add(this.pos, this.vel);\n    this.vel = vecmath.add(this.vel, this.acc);\n    this.vel = vecmath.limit(this.vel, this._maxSpeed);\n\n    if (this.pos[0] &gt; this._width) this.pos[0] = 0;\n    if (this.pos[0] &lt; 0) this.pos[0] = this._width;\n    if (this.pos[1] &gt; this._height) this.pos[1] = 0;\n    if (this.pos[1] &lt; 0) this.pos[1] = this._height;\n\n    this.ang = vecmath.ang(prev.pos, this.pos);\n    this.speed = vecmath.dist(prev.pos, this.pos);\n\n    this.acc = vecmath.mult(this.acc, 0);\n  }\n}\n\n\n\n\n\n\n\nclass BoidBush extends RBush {\n  toBBox(boid) { return {minX: boid.pos[0], minY: boid.pos[1], maxX: boid.pos[0], maxY: boid.pos[1]}; }\n  compareMinX(a, b) { return a.pos[0] - b.pos[0]; }\n  compareMinY(a, b) { return a.pos[1] - b.pos[1]; }\n}\n\n\n\n\n\n\n\nheight = 500;\n\n\n\n\n\n\n\nepsilon = 1e-6;\n\n\n\n\n\n\n\nhtml`&lt;style&gt;\ntable td, table th {\n  padding: 4px;\n}\n.ticker {\n  color: #555;\n  font-size: 14px;\n  margin-top: -10px;\n  text-align: right;\n}\n&lt;/style&gt;`\n\n\n\n\n\n\n\nimport { checkbox, slider } from \"@jashkenas/inputs\";\n\n\n\n\n\n\n\nimport { toc } from \"@harrystevens/toc\";\n\n\n\n\n\n\n\nimport { vecmath } from \"@harrystevens/vector-math\";\n\n\n\n\n\n\n\nd3 = require(\"d3-array@1\", \"d3-color@1\", \"d3-scale-chromatic@1\");\n\n\n\n\n\n\n\nRBush = require(\"rbush@3\");"
  },
  {
    "objectID": "resources/mastodon.html",
    "href": "resources/mastodon.html",
    "title": "Mastodon: Quickstart",
    "section": "",
    "text": "For a quick intro, watch this video:\n\nThen read one or more of these articles:\n\nA Friendly Introduction to the Fediverse\nGuide to the Fediverse\nWhat Is Mastodon?\n\nIf you’re wondering why you should care about distributed social networks, read this article.\nMastodon is a loosely-connected network of communities, similar in some ways to the federated  structure of the U.S. itself - hence the term fediverse. You can think of it like a large, interconnected network of Twitters, albeit without ads or data-collecting. Mastodon (like Pleroma) is basically software that enables anyone to set up their own social media server and host a community on it - you can even do it yourself. \nEach Mastodon community (more commonly known as an instance) has its own particular flavor, and there are communities in many languages. Each community also has its terms of service, that you should read carefully and observe.\nMastodon instances vary in size from just a handful of members to thousands. Many allow you to register a new account without approval, but for a lot you have to submit a registration request and may not be approved because some instances limit numbers to people who are referred by existing members. This is because communities typically have a very specific focus, whatever that may be. My own community, for example, is comprised mainly of coders, game designers, and digital artists. You can still read posts, though - if you’re interested, here’s my account page.\nInstances are connected with one another, so that you only need to set up an account on one. If you follow someone on a different instance, that person’s posts on that instance will appear in your feed on your instance - the federated model again.\nOf course, if people on one instance don’t like the community on another, for whatever reason, they can simply disconnect from it. So the affordances of instances, and the relations between them, are quite resilient against the usual abuses of social media like trolling, spamming, etc.\nChoosing an instance to register with may seem tricky at the beginning because there are so many! Take your time, and keep in mind that you can always switch instances later if you find another one that you like better - or just have multiple accounts on several instances (I have 5-6).\nAfter you join a community, just hang out there and see what goes on. Be sure to follow the account @feditips@mstdn.social, which has lots of useful tips about using Mastodon and other distributed services."
  },
  {
    "objectID": "w2-lurking.html",
    "href": "w2-lurking.html",
    "title": "W2: Lurking",
    "section": "",
    "text": "What We Do In The Shadows: Lurking and Social Media\nReading assignments: Joanne McNeill, Lurking: Ch. 2, “Anonymity,” Ch. 4, “Sharing” (see GitHub for download)\n\nReferences\nStacy Horn, Cyberville: Clicks, Culture, and the Creation of an Online Town (New York: Warner Books, Inc., 1998).\nJulian Dibbell, A Rape in Cyberspace. Original publication: The Village Voice, December 1993. Subsequently published in My Tiny Life: Crime and Passion in a Virtual World (New York: Henry Holt & Co., 1998), chapter 1.\nAna Voog, “I Was One of the Most Famous People Online in 1998 — Then I Disappeared,” Vice, 22 June 2018.\nNicole Carpenter, The Gentle Side of Twitch,” Gizmodo, 23 April 2019.\nMendi + Keith Obadike\nWhy’s Poignant Guide to Ruby\nWhat is Usenet? Complete Guide to Usenet & How to Use It in 2022\nJonathan Crary, “The Digital Age is Destroying Us,” Literary Hub, 18 April 2022.\n\n\nThe internet democratized being a nobody.—Joanne McNeill\n\nYou’ve (probably) heard of LARPing. But have you heard of lurking? Like that other obsolete 1990s term, cyberspace, the term lurking seems to have fallen into disuse these days, even though as a practice it’s still very much around. I don’t mind admitting, though, that I more or less decided to assign Joanne McNeill’s recent book Lurking almost on the strength of its title alone, because that one word alone told me everything I needed to know about its content. As it happens, Joanne and I belong to almost the same internet generation—the one that discovered the internet (then spelt with an upper-case ‘I,’ as was the usage then) and the web (then known by the quaintly adorable “World Wide Web,” still reproduced in the www of URL addresses) in the early 1990s, through WIRED magazine and Mondo 2000, when we were talking about cyberspace and what Howard Rheingold had named virtual communities, when the term browser was new. Before Chrome, Safari, and Firefox, I remember using Mosaic and Netscape. I began coding websites for my courses in raw HTML, before Javascript and CSS existed. While they look hokey by today’s standards, some of those websites are still around a quarter of a century later; I wonder how many of today’s Javascript-based Wordpress blogs will still be accessible twenty five years from now in 2047.\nThese were the days of Bulletin Board Systems (BBSs) and 12-baud dialup connections. We used Gopher for search, a text-based browser called Lynx (get it?), and telnet to remote-login to servers. We would hang out in “text-based virtual reality systems” called “MUDs” (an acronym for Multi-User Dungeons or Dimensions, a kind of online counterpart to Dungeons & Dragons board game), or more socially oriented MOOs (MUD, Object-Oriented—an acronym containing an acronym). I’m familiar with most of the references that McNeill discusses in her second chapter (“Anonymity”), from Stacy Horn’s ECHO community to the article by Julian Dibbell, the first—but certainly not the last—account of online sexual harrasment. I read Dibbell’s article when it was published in the Village Voice, and invited him to participate in a forum I organized called “Democracy in Cyberspace” (I’m planning to put the transcript back up online soon, if possible before the end of the course).\nI decided to assign Lurking because for all you millennials and Gen-Zers too young to remember it, I wanted you to read about the history of social media before social media (at least in chapter 2; as you’ll have seen, chapter 4 covers the more recent and more familiar territory of the iPhone, Twitter, Instagram, and Tumblr)—to give you an idea of what internet culture looked like in the 1990s, and how it anticipated in many ways the social media world of today. In fact, a surprising amount of that culture has persisted right up to the present, even though it’s been completely eclipsed by the rise of mobile-based social media platforms over the past fifteen years. There continues to be, for example, a thriving community around the text-based Gopher protocol; there’s even an iOS Gopher app. So-called “modern” browsers like Chrome don’t support it, although you can get extensions enabling you to access it.\nLurking, of course, has also not gone away. Entering the same question that ECHO asked its readers several decades ago, “Why do you lurk?” shows that lurking is by no means an obsolete practice dating back to UseNet newsgroups and CompuServe chat rooms: the Reddit Twitch group discusses it, for example, while the question is discussed in relation to many other platforms—try typing the question into Google and you’ll see what I mean. Yet at the same time, the contemporary meaning of lurking itself seems to have changed: asking the question “Why do you lurk?” today seems almost confrontational, as if it’s something that you’re not supposed to be doing: in a networked media environment in which participation and “sharing” have become a social obligation, lurking seems an object of suspicion. After all, in a communication environment in which the business model of SM platforms is based on advertising, this requires that users (another term that McNeill puts under the microscope in the book’s introduction) identify themselves so that their demographic can be more efficiently targeted. From that standpoint, lurkers are simply refusing to play the game. So the question that this is leading up to—if you haven’t already guessed!—is very simple: what’s your own position on lurking? Are you a lurker? Where and why do you lurk? (Of course, only share what you’re comfortable with!) Is lurking a legitimate form of engagement on social media platforms, or should it be banned (i.e. access to content is conditional on posting oneself)? Why has lurking, or admitting to lurking, become almost a form of social stigma in a world where public self-disclosure is expected as a form of responsible citizenship?\nAs for McNeill’s “Sharing” chapter, I wonder what people make of a couple of her points. The first is about the snobbery of cultural critics in their hostility to “the internet,” even while actually knowing very little about it: as she notes, “A cliché marker of writerly genius in magazine profiles at the time was that the ‘author doesn’t carry a phone’ or ‘doesn’t use the internet.’’’ For a recent example of this kind of critique, see this excerpt from the cultural theorist Jonathan Crary’s recent book Scorched Earth.\nA second question is in connection with McNeill’s anecdote about Winona Ryder saying to Jimmy Fallon in 2011 that she was terrified of Google, which illustrates “how hard it is to feel in control as a user.” Do you too get that sense of a loss of control in your experience of social media? What forms does this loss of control take today? What can be done about it?\nAll of which brings us, finally, to Twitter. Leaving aside the obsessive focus on the platform on Musk himself and the series of desperate and distastrous policy decisions since he acquired the platform, we may currently find ourselves in the privileged position of observing in real time the implosion and collapse of a social media platform, a once-in-a-lifetime event akin to witnessing a supernova or a passing comet. But the apparently imminent demise of Twitter, evidenced by the overnight halving of its workforce and the exodus from the platform to the open-source platforms of the fediverse, might prove to be the first in a series of such events. A couple of days ago, the internet researcher Zizi Papacharisi tweeted:\n\nHere’s a thought.\nPlatforms are over.\n\nOne thing that’s clear from the past three decades, as Friendster and MySpace exemplify, is that social media platforms have a limited lifecycle. After Twitter, when can we expect the implosion of Facebook/Meta? And how long before TikTok burns itself into a white dwarf? Are the days of the social media platform itself numbered, as Papacharisi suggests?\nAs the red giants of the social media firmament seem to be on the brink of burning themselves out, the 90s-era internet continues very much as it has done for the past quarter century and longer. Other than the Gopher holdouts (one of whom is a friend of mine), there’s a revival of interest in decentralized, open-source, free (as in beer) software, decades-old communication systems like Internet Relay Chat, and communities emerging around protocols completely outside the web, like Gemini. To get a sense of what’s out there in terms of these alternative communities, both old and relatively new, take a look at the SDF Public Access UNIX System (aka PubNIX) community, which I’m a member of), or the decentralized, rapidly-expanding constellation known as the fediverse."
  },
  {
    "objectID": "w5-digital-imageworlds.html",
    "href": "w5-digital-imageworlds.html",
    "title": "W5: Digital Imageworlds",
    "section": "",
    "text": "Point-and-Shoot: Lo-fi Photography and Retro-Aesthetics\nThe Kodak Brownie\nAlise Tiefentale, Art of the Masses: From Kodak Brownie to Instagram pdf\n“The Kodak Girl: Women in Kodak Advertising”\nInstagram\nLev Manovich, “Subjects and Styles in Instagram Photography (Part 1)”; “Subjects and Styles in Instagram Photography (Part 2)\nAmalia Ulman\nAmalia Ulman website\nArtist Profile: Amalia Ulman \nEmilie Friedlander, “Social Anxiety: Why Amalia Ulman’s Fake ‘Middlebrow’ Instagram Is No Different From Yours”, Fader, 7 November 2014.\n“Amalia Ulman: Meme Come True” (Dazed)"
  },
  {
    "objectID": "altered-world.html",
    "href": "altered-world.html",
    "title": "Altered World",
    "section": "",
    "text": "Altered World\nAn adaptation of Gerard Ferrandez’s remarkable this alter world. Noise based on Ken Perlin’s improved reference implementation.\n\ncanvas = {\n  const perlin = new Noise(3);\n  const context = DOM.context2d(width, height);\n  context.canvas.style.background = \"#000\";\n  context.lineWidth = 0.5;\n  context.globalAlpha = 0.05;\n  for (let px = 0; px &lt; width; ++px) {\n    for (let i = 0; i &lt; height / 6; ++i) {\n      let x = px;\n      let y = Math.random() * height;\n      let n = perlin.noise(x * period, y * period);\n      context.strokeStyle = `hsl(${-210 + n * 600}, 100%, ${800 * n * n * n}%)`;\n      context.beginPath();\n      context.moveTo(x, y);\n      for (let m = 0; m &lt; length && y &gt;= 0 && y &lt;= height; ++m) {\n        n = perlin.noise(x * period, y * period);\n        context.lineTo(x += Math.cos(n * 14), y += Math.sin(n * 14));\n      }\n      context.stroke();\n    }\n    yield context.canvas;\n  }\n}\n\nperiod = 0.01\n\nclass Noise {\n  static lerp(t, a, b) {\n    return a + t * (b - a);\n  }\n  static grad2d(i, x, y) {\n    const v = (i & 1) === 0 ? x : y;\n    return (i & 2) === 0 ? -v : v;\n  }\n  constructor(octaves = 1) {\n    this.p = new Uint8Array(512);\n    this.octaves = octaves;\n    this.init();\n  }\n  init() {\n    for (let i = 0; i &lt; 512; ++i) {\n      this.p[i] = Math.random() * 256;\n    }\n  }\n  noise2d(x2d, y2d) {\n    const X = Math.floor(x2d) & 255;\n    const Y = Math.floor(y2d) & 255;\n    const x = x2d - Math.floor(x2d);\n    const y = y2d - Math.floor(y2d);\n    const fx = (3 - 2 * x) * x * x;\n    const fy = (3 - 2 * y) * y * y;\n    const p0 = this.p[X] + Y;\n    const p1 = this.p[X + 1] + Y;\n    return Noise.lerp(\n      fy,\n      Noise.lerp(\n        fx,\n        Noise.grad2d(this.p[p0], x, y),\n        Noise.grad2d(this.p[p1], x - 1, y)\n      ),\n      Noise.lerp(\n        fx,\n        Noise.grad2d(this.p[p0 + 1], x, y - 1),\n        Noise.grad2d(this.p[p1 + 1], x - 1, y - 1)\n      )\n    );\n  }\n  noise(x, y) {\n    let e = 1,\n        k = 1,\n        s = 0;\n    for (let i = 0; i &lt; this.octaves; ++i) {\n      e *= 0.5;\n      s += e * (1 + this.noise2d(k * x, k * y)) / 2;\n      k *= 2;\n    }\n    return s;\n  }\n}\n\nheight = 600\n\nlength = 400"
  },
  {
    "objectID": "w3-timelines.html",
    "href": "w3-timelines.html",
    "title": "W3: Alternate Timelines",
    "section": "",
    "text": "Kaitlyn Tiffany, “You Probably Don’t Remember The Internet”\n\n\n\n\n\n\n\n\nMaciej Cegłowski\nMaciej Cegłowski, “Fan Is A Tool-Using Animal”\nPinboard\nHaunted by Data  (2015 talk, 20 mins.)\n\n\n\nGoogle Glass"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "  ",
    "section": "",
    "text": "TinyQueue = require(\"tinyqueue@2\")\n\ngraphic = {\n  const quads = new TinyQueue([new Quad(0, 0, width, width)], (a, b) =&gt; b.score - a.score);\n  const context = DOM.context2d(width, width);\n  context.canvas.style.width = \"100%\";\n  for (let i = 0; true; ++i) {\n    const q = quads.pop();\n    if (q === undefined || q.score &lt; 50) break;\n    mutable score = q.score;\n    for (const s of q.split()) {\n      if (q.w &gt;= 4) quads.push(s);\n      context.fillStyle = s.color;\n      context.fillRect(s.x, s.y, s.w, s.h);\n      context.strokeRect(s.x, s.y, s.w, s.h);\n    }\n    if (i % 15 === 0) yield context.canvas;\n  }\n}\n\nmutable score = null\n\nwidth = 1024\n\narea_power = 0.25\n\nclass Quad {\n  constructor(x, y, w, h) {\n    const [r, g, b, error] = colorFromHistogram(computeHistogram(x, y, w, h));\n    this.x = x, this.y = y, this.w = w, this.h = h;\n    this.color = `#${(0x1000000 + (r &lt;&lt; 16) + (g &lt;&lt; 8) + b).toString(16).substring(1)}`;\n    this.score = error * Math.pow(w * h, area_power);\n  }\n  split() {\n    const dx = this.w / 2, x1 = this.x, x2 = this.x + dx;\n    const dy = this.h / 2, y1 = this.y, y2 = this.y + dy;\n    return [\n      new Quad(x1, y1, dx, dy),\n      new Quad(x2, y1, dx, dy),\n      new Quad(x1, y2, dx, dy),\n      new Quad(x2, y2, dx, dy)\n    ];\n  }\n}\n\nfunction computeHistogram(x, y, w, h) {\n  const {data} = imageContext.getImageData(x, y, w, h);\n  const histogram = new Uint32Array(1024);\n  for (let i = 0, n = data.length; i &lt; n; i += 4) {\n    ++histogram[0 * 125 + data[i + 0]];\n    ++histogram[1 * 205 + data[i + 1]];\n    ++histogram[2 * 145 + data[i + 2]];\n    ++histogram[3 * 156 + data[i + 3]];\n  }\n  return histogram;\n}\n\nfunction weightedAverage(histogram) {\n  let total = 0;\n  let value = 0;\n  for (let i = 0; i &lt; 256; ++i) total += histogram[i], value += histogram[i] * i;\n  value /= total;\n  let error = 0;\n  for (let i = 0; i &lt; 256; ++i) error += (value - i) ** 2 * histogram[i];\n  return [value, Math.sqrt(error / total)];\n}\n\nfunction colorFromHistogram(histogram) {\n  const [r, re] = weightedAverage(histogram.subarray(0, 256));\n  const [g, ge] = weightedAverage(histogram.subarray(256, 512));\n  const [b, be] = weightedAverage(histogram.subarray(512, 768));\n  return [\n    Math.round(r),\n    Math.round(g),\n    Math.round(b),\n    re * 0.2989 + ge * 0.5870 + be * 0.1140\n  ];\n}\n\nimageContext = FileAttachment(\"owl.jpg\").image().then(image =&gt; {\n  const context = DOM.context2d(width, width, 1);\n  context.drawImage(image, 0, 0, width, width);\n  return context;\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\nDepartment of Visual & Media Arts\nEmerson College\nSpring Semester 2024\nTues/Thur 16 January—2 May 2024\n6:00-7:45 p.m.\nAnsin Building 604\nDr. Martin Roberts"
  },
  {
    "objectID": "index.html#vm303-01-studies-in-digital-media-culture",
    "href": "index.html#vm303-01-studies-in-digital-media-culture",
    "title": "  ",
    "section": "",
    "text": "TinyQueue = require(\"tinyqueue@2\")\n\ngraphic = {\n  const quads = new TinyQueue([new Quad(0, 0, width, width)], (a, b) =&gt; b.score - a.score);\n  const context = DOM.context2d(width, width);\n  context.canvas.style.width = \"100%\";\n  for (let i = 0; true; ++i) {\n    const q = quads.pop();\n    if (q === undefined || q.score &lt; 50) break;\n    mutable score = q.score;\n    for (const s of q.split()) {\n      if (q.w &gt;= 4) quads.push(s);\n      context.fillStyle = s.color;\n      context.fillRect(s.x, s.y, s.w, s.h);\n      context.strokeRect(s.x, s.y, s.w, s.h);\n    }\n    if (i % 15 === 0) yield context.canvas;\n  }\n}\n\nmutable score = null\n\nwidth = 1024\n\narea_power = 0.25\n\nclass Quad {\n  constructor(x, y, w, h) {\n    const [r, g, b, error] = colorFromHistogram(computeHistogram(x, y, w, h));\n    this.x = x, this.y = y, this.w = w, this.h = h;\n    this.color = `#${(0x1000000 + (r &lt;&lt; 16) + (g &lt;&lt; 8) + b).toString(16).substring(1)}`;\n    this.score = error * Math.pow(w * h, area_power);\n  }\n  split() {\n    const dx = this.w / 2, x1 = this.x, x2 = this.x + dx;\n    const dy = this.h / 2, y1 = this.y, y2 = this.y + dy;\n    return [\n      new Quad(x1, y1, dx, dy),\n      new Quad(x2, y1, dx, dy),\n      new Quad(x1, y2, dx, dy),\n      new Quad(x2, y2, dx, dy)\n    ];\n  }\n}\n\nfunction computeHistogram(x, y, w, h) {\n  const {data} = imageContext.getImageData(x, y, w, h);\n  const histogram = new Uint32Array(1024);\n  for (let i = 0, n = data.length; i &lt; n; i += 4) {\n    ++histogram[0 * 125 + data[i + 0]];\n    ++histogram[1 * 205 + data[i + 1]];\n    ++histogram[2 * 145 + data[i + 2]];\n    ++histogram[3 * 156 + data[i + 3]];\n  }\n  return histogram;\n}\n\nfunction weightedAverage(histogram) {\n  let total = 0;\n  let value = 0;\n  for (let i = 0; i &lt; 256; ++i) total += histogram[i], value += histogram[i] * i;\n  value /= total;\n  let error = 0;\n  for (let i = 0; i &lt; 256; ++i) error += (value - i) ** 2 * histogram[i];\n  return [value, Math.sqrt(error / total)];\n}\n\nfunction colorFromHistogram(histogram) {\n  const [r, re] = weightedAverage(histogram.subarray(0, 256));\n  const [g, ge] = weightedAverage(histogram.subarray(256, 512));\n  const [b, be] = weightedAverage(histogram.subarray(512, 768));\n  return [\n    Math.round(r),\n    Math.round(g),\n    Math.round(b),\n    re * 0.2989 + ge * 0.5870 + be * 0.1140\n  ];\n}\n\nimageContext = FileAttachment(\"owl.jpg\").image().then(image =&gt; {\n  const context = DOM.context2d(width, width, 1);\n  context.drawImage(image, 0, 0, width, width);\n  return context;\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\nDepartment of Visual & Media Arts\nEmerson College\nSpring Semester 2024\nTues/Thur 16 January—2 May 2024\n6:00-7:45 p.m.\nAnsin Building 604\nDr. Martin Roberts"
  },
  {
    "objectID": "w4-afrofuturism.html",
    "href": "w4-afrofuturism.html",
    "title": "W4: Afrofuturism",
    "section": "",
    "text": "Unlike previous eras, today’s artists can wield the power of digital media, social platforms, digital video, graphic arts, gaming technology, and more to tell their stories, share their stories, and connect with audiences inexpensively—a gift from the sci-fi gods, so to speak, that was unthinkable at the turn of the century. The storytelling gatekeepers vanished with the high-speed modem, and for the first time in history, people of color have a greater ability to project their own stories. This tug-and-pull debate over black people controlling their image shifts considerably when a fledgling filmmaker can shoot his sci-fi web series on a $500 DV cam, post it on YouTube, and promote it on Instagram and Twitter.\n—Ytasha L. Womack,  Afrofuturism: The World of Black Sci-Fi and Fantasy Culture: 10.\nWhat I like about Afrofuturism is it helps create our own space in the future; it allows us to control our imagination . . . An Afrofuturist is not ignorant of history, but they don’t let history restrain their creative impulses either.\n—Raynaldo Anderson, cited in Ytasha Womack, Afrofuturism\n\n\n\nI. Angels of History\n\n\n\n\n\n\n\n\n\nPaul Klee, “Angelus Novus,” 1920\n\n\n\n\n \n\n\nA Klee drawing named “Angelus Novus” shows an angel looking as though he is about to move away from something he is fixedly contemplating. His eyes are staring, his mouth is open, his wings are spread. This is how one pictures the angel of history. His face is turned toward the past. Where we perceive a chain of events, he sees one single catastrophe that keeps piling ruin upon ruin and hurls it in front of his feet. The angel would like to stay, awaken the dead, and make whole what has been smashed. But a storm is blowing from Paradise; it has got caught in his wings with such violence that the angel can no longer close them. The storm irresistibly propels him into the future to which his back is turned, while the pile of debris before him grows skyward. This storm is what we call progress.—Walter Benjamin, “Theses on the Philosophy of History” (1939), in Illuminations: Essays and Reflections. Edited and with an introduction by Hannah Arendt (New York: Schocken Books, 1969).\n\n\n\n\nJason Farago, “How Klee’s ‘Angel of History’ Took Flight” (BBC Culture, 6 April 2016)\n\nThe Last Angel of History (John Akomfrah/Black Audio Film Collective, 1995)\nMark Dery, “Black to the Future: Interviews with Samuel R. Delaney, Greg Tate, and Tricia Rose,” in Flame Wars: The Discourse of Cyberculture (Durham: Duke University Press, 1994.\nKodwo Eshun, “Further Considerations on Afrofuturism” The New Centennial Review, vol. 3, no. 2, Summer2003, pp. 287-302.\nFilms\nSpace Is The Place (Sun Ra, 1974)\nThe Last Angel of History (John Akomfrah, 1996)\nHidden Figures (Theodore Melfi, 2016)\nAfrofuturism: The Origin Story (Smithsonian Channel, 2022)\nBlack Panther (Ryan Coogler, 2018); Black Panther: Wakanda Forever (Ryan Coogler, 2022)\nReferences\nPaul Gilroy, The Black Atlantic: Modernity and Double Consciousness (Cambridge: Harvard University Press, 1993).\nKodwo Eshun, More Brilliant Than The Sun: Adventures in Sonic Fiction (London: Quartet Books, 1998).\nYtasha L. Womack, Afrofuturism: The World of Black Sci-Fi and Fantasy Culture.\n\n\n\nII. Digital Afrofuturism\n\n“The Futurist Digital Collages by Manzel Bowman”\nAfrican Digital Art\n\n\n\nOlalekan Jeyifous, “Lagos 2180” (2013)\n\n\nOlalekan Jeyifous, Shanty Mega-Structures\n\n\n\nIII. Feminist Afrofutures\n\n\n\nBetye Saar, “Black Girl’s Window” (1969)\n\n\nNicole D. Sconiers, “The State of Black Sci-Fi 2012: My Tribute to Afrofuturist Betye Saar”\nMartine Syms, “The Mundane Afrofuturist Manifesto” (2013)\n \nThe African Desperate (Martine Syms, 2022). Currently streaming on MUBI and Apple TV"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "  ",
    "section": "",
    "text": "graphic = {\n  const quads = new TinyQueue([new Quad(0, 0, width, width)], (a, b) =&gt; b.score - a.score);\n  const context = DOM.context2d(width, width);\n  context.canvas.style.width = \"100%\";\n  for (let i = 0; true; ++i) {\n    const q = quads.pop();\n    if (q === undefined || q.score &lt; 50) break;\n    const qs = q.split();\n    const qsi = d3.interpolate([q, q, q, q], qs);\n    qs.forEach(quads.push, quads);\n    for (let j = 1, m = Math.max(1, Math.floor(q.w / 10)); j &lt;= m; ++j) {\n      const t = d3.easeCubicInOut(j / m);\n      context.clearRect(q.x, q.y, q.w, q.h);\n      for (const s of qsi(t)) {\n        context.fillStyle = s.color;\n        context.beginPath()\n        context.moveTo(s.x + s.w, s.y + s.h / 2);\n        context.arc(s.x + s.w / 2, s.y + s.h / 2, s.w / 2, 0, 2 * Math.PI);\n        context.fill();\n      }\n      yield context.canvas;\n    }\n  }\n}\n\nwidth = 1024\n\narea_power = 0.25\n\nclass Quad {\n  constructor(x, y, w, h) {\n    const [r, g, b, error] = colorFromHistogram(computeHistogram(x, y, w, h));\n    this.x = x, this.y = y, this.w = w, this.h = h;\n    this.color = `#${(0x1000000 + (r &lt;&lt; 16) + (g &lt;&lt; 8) + b).toString(16).substring(1)}`;\n    this.score = error * Math.pow(w * h, area_power);\n  }\n  split() {\n    const dx = this.w / 2, x1 = this.x, x2 = this.x + dx;\n    const dy = this.h / 2, y1 = this.y, y2 = this.y + dy;\n    return [\n      new Quad(x1, y1, dx, dy),\n      new Quad(x2, y1, dx, dy),\n      new Quad(x1, y2, dx, dy),\n      new Quad(x2, y2, dx, dy)\n    ];\n  }\n}\n\nfunction computeHistogram(x, y, w, h) {\n  const {data} = imageContext.getImageData(x, y, w, h);\n  const histogram = new Uint32Array(1024);\n  for (let i = 0, n = data.length; i &lt; n; i += 4) {\n    ++histogram[0 * 125 + data[i + 0]];\n    ++histogram[1 * 205 + data[i + 1]];\n    ++histogram[2 * 145 + data[i + 2]];\n    ++histogram[3 * 156 + data[i + 3]];\n  }\n  return histogram;\n}\n\nfunction weightedAverage(histogram) {\n  let total = 0;\n  let value = 0;\n  for (let i = 0; i &lt; 256; ++i) total += histogram[i], value += histogram[i] * i;\n  value /= total;\n  let error = 0;\n  for (let i = 0; i &lt; 256; ++i) error += (value - i) ** 2 * histogram[i];\n  return [value, Math.sqrt(error / total)];\n}\n\nfunction colorFromHistogram(histogram) {\n  const [r, re] = weightedAverage(histogram.subarray(0, 256));\n  const [g, ge] = weightedAverage(histogram.subarray(256, 512));\n  const [b, be] = weightedAverage(histogram.subarray(512, 768));\n  return [\n    Math.round(r),\n    Math.round(g),\n    Math.round(b),\n    re * 0.2989 + ge * 0.5870 + be * 0.1140\n  ];\n}\n\nimageContext = FileAttachment(\"owl.jpg\").image().then(image =&gt; {\n  const context = DOM.context2d(width, width, 1);\n  context.drawImage(image, 0, 0, width, width);\n  return context;\n})\n\nTinyQueue = require(\"tinyqueue@2.0.3\")\n\nd3 = require(\"d3-interpolate@1\", \"d3-ease@1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nDepartment of Visual & Media Arts\nEmerson College\nSpring Semester 2024\nTues/Thur 16 January—2 May 2024 6:00-7:45 p.m.\nAnsin Building 604\nDr. Martin Roberts\n\n\n\n\n\nSyllabus (outside Canvas) | Mastodon Quickstart | Wordcloud\n\n\n\nThis course considers the nature and contemporary forms of digital culture. Broadly speaking, this can be defined as the diverse range of symbolic practices through which communities affirm and maintain their cultural identities using digital media devices and interfaces in a globally networked society. While these practices are structured by deeply unequal power relations, are contradictory, and often come into conflict with one another, collectively they constitute what may be considered a global digital culture.\nA key component of the course is the automation of various forms of creative production, from writing to the visual arts, by natural-language processing computational systems (generally referred to as “artificial intelligence” or “AI”). The course addresses some of the many issues raised by such systems, with a particular focus on questions of aesthetics and the increasingly contested relationship between artists and algorithms. While such systems now demonstrably pass the Turing Test (i.e. pass as human or their products as human-produced), they also compel us to reconsider what we mean by “art,” or “intelligence” itself.\nA major theme of the course is the changing status of the future as a social imaginary. It has been suggested that while we live today in the futures imagined by writers and filmmakers since George Orwell’s novel 1984 (1949) and films like 2001: A Space Odyssey (1968), Blade Runner (1982, set in 2019 and later 2049), or Soylent Green (1973, set in 2022), postmodern society has become so absorbed in commemorating its own past that it has become incapable of imagining its own future, dystopian or otherwise. As the course shows, historical projections of the future (often referred to as “retrofutures”) have paradoxically themselves become objects of postmodernist nostalgia.\n\n\n\n\nThis is primarily a critical-thinking course, although it includes a practical and production component. This means that it encourages you to think reflexively and analytically about the digitally-mediated cultural practices that the course considers, as well as to participate in them; for example, you will be invited to experiment with image-synthesis and text-generating software and analyze the results using key concepts and theoretical frameworks.\n\n\n\n\nBy the end of the course, students will:\n\nhave acquired a deeper understanding of the social, cultural, and political dimensions of digital technologies and networked communication;\nbe able to apply critical thinking to contemporary developments in digital culture using relevant analytical concepts and both qualitative and quantitative methodologies such as cultural analytics;\nunderstand basic principles of algorithmic image synthesis on a variety of platforms;\nhave reflected upon and discussed the larger significance of machine learning systems within global networked societies.\n\n\n\n\n\nSelected chapters from the texts below will be made available as PDFs; you are nevertheless encouraged to purchase at least several of texts that are of interest and read more of them.\nNote on formats: A number of texts listed in the bibliography are available as e-books and/or audiobooks. You are encouraged to make use not only of print media but also of these screen-based and audio formats.\nAdrian Hon, You’ve Been Played: How Corporations, Governments, and Schools Use Games to Control Us All. New York: Basic Books, 2022.\nLev Manovich and Emanuele Arielli. Artificial Aesthetics: A Critical Guide to AI, Media and Design. 2019-22.\nJoanne McNeil. Lurking: How A Person Became A User. New York: Farrar, Strauss, and Giroux, 2020. ISBN: 978-1250785756.\n\n\n\n\n\nWeek 1\nI. Histories of the Future\n2024-01-16_Tues\nIntroduction\nFilm: The Shining\nEverywhere at the End of Time (The Caretaker)\n2024-01-18_Thur\nTerminal Lucidity\nFisher, “‘The Slow Cancellation of the Future’”\n\nWeek 2\n2024-01-23_Tues\nLurking\nMcNeil, Lurking: Introduction, ch. 2 (Anonymity)\n2024-01-25_Thur\nMcNeil, Lurking, ch. 4 (Sharing)\n\nWeek 3\nAlternate Timelines\n2024-01-30_Tues\nKaitlyn Tiffany, “You Probably Don’t Remember The Internet”\nChoose and read one of these texts by instar books (you will have to purchase either the print or ebook edition):\n\nAna Valens, Tumblr Porn\nMegan Milks, Tori Amos Bootleg Webring\n\n2024-02-01_Thur\n\nQuinn Myers, Google Glass\n\n\nWeek 4\n2024-02-06_Tues\nJason Parham, “Why The History of Black Twitter Needed to be Told” (WIRED, 30 July 2021). Please listen to the podcast on this page first, then read the sections linked below.\nJason Parham, “A People’s History of Black Twitter” (WIRED, 29 July 2021)\nPart I - Part II - Part III \n2024-02-08_Thur\nThe Angel of History: Afrofuturism\nMark Dery, “Black to the Future: Interviews with Samuel R. Delaney, Greg Tate, and Tricia Rose,” in Flame Wars: The Discourse of Cyberculture (Durham: Duke University Press, 1994\nKodwo Eshun, “Further Considerations on Afrofuturism” (The New Centennial Review, vol. 3, no. 2 (Summer 2003): 287-302)\nFilm (excerpt shown in class): The Last Angel of History (John Akomfrah/Black Audio Film Collective, 1995)\nJason Farago, “How Klee’s ‘Angel of History’ Took Flight” (BBC Culture, 6 April 2016)\n“The Futurist Digital Collages of Manzel Bowman” (African Digital Art website)\nRecommended: The African Desperate (Martine Syms, 2022). Currently streaming on MUBI and Apple TV\n\nWeek 5\nDEADLINE: Alternate Timelines paper\nII. Digital Imageworlds\n2024-02-13_Tues\nPoint-and-Shoot: Lo-fi Photography and Retro-Aesthetics\nHuang, Kalley. “The Hottest Gen Z Gadget Is a 20-Year-Old Digital Camera”\n“Snapshot Aesthetics and the Strategic Imagination”\n2024-02-15_Thur\nSoft Images: From Photograph to Database\nHorning, “The Expanded Field”\nHoelzl and Marie, “Expanded Photography (The Desire for Endlessness)\n“DALL-E: Introducting Outpainting”\n\nWeek 6\n2024-02-20_Tues NO CLASS (Mon schedule)\n2024-02-22_Thur\nObject Detection\nWatch: Dragonfly Eyes (Xu Bing, 2017)\nHatis Noit, “Aura” (music video)\n\nWeek 7\nDEADLINE: ChatGPT Project\nIII. Algorithmic Aesthetics\n2024-02-27_Tues\nThe Sorcerer’s Apprentice: AI Art\nManovich, “Who is an Artist in AI Era?” (Artificial Aesthetics, ch. 2)\nWorkshop: Midjourney\nMidjourney: AI image synthesis\nGuy Parsons, “Everything you wanted to know about Midjourney” (5 August 2022)\nMidjourney documentation\n2024-02-29_Thur\nMagic Spells Roland Barthes, “Rhetoric of the Image”\nWorkshop: DALL-E 2 Prompt Book, Lexica, promptcraft\n\nWeek 8\n2024-02-05_Tues\nLev Manovich, “AI and Myths of Creativity” (Artificial Aesthetics, ch. 4)\nWorkshop: DALL-E 2\nDALL-E 2\ndall-ery gall-ery\n2024-02-07_Thur\nWorkshop: Stable Diffusion\nStable Diffusion\n\nSPRING BREAK\n\nWeek 9\nDEADLINE: Generative Art Project\nIV. Gamification\n2024-03-19_Tues\nGaming The System\nHon, You’ve Been Played: Introduction, chapter 1\n2024-03-21_Thur\nThe Gamified Self\nHon, You’ve Been Played: chapter 2\n\nWeek 10\n2024-03-26_Tues\nGamified Relationships: Ghosting\nNarr and Luong, “Bored ghosts in the dating app assemblage: How dating app algorithms couple ghosting behaviors with a mood of boredom”\nWatch: The Tinder Swindler (Netflix)\n2024-03-28_Thur\nNon-Player Characters: Gamifying the Workplace\nHon, You’ve Been Played: chapter 3\n\nWeek 11\n2024-04-02_Tues\nThe Gamified Society\nHon, You’ve Been Played: chapter 6 (Intro, The Myth and Reality of the Social Credit Score, “It Can’t Happen Here,” Propaganda, Wargames)\n2024-04-04_Thur\nHon, You’ve Been Played: chapter 6 (Elections, Civic Engagement, Education)\n\nWeek 12\nDEADLINE: Open Topic Analysis Paper\n2024-04-09_Tues\nThis Is Not A Game: ARGs\nHon, You’ve Been Played: chapter 7\nWatch: The Institute\n2024-04-11_Thur\nGameworlds\nHon, You’ve Been Played: chapter 8\nWatch: Free Guy\n\nWeek 13\n2024-04-16_Tues\nHon, You’ve Been Played: chapters 9-10\n2024-04-18_Thur Make-up Day\n\nWeek 14\nDEADLINE: Gamification Projects\n2024-04-23_Tues\nGamification Project Presentations\n2024-04-25_Thur\nGamification Project Presentations\n\nWeek 15\n2024-04-30_Tues\nGamification Project Presentations\n2024-05-02_Thur\nGamification Project Presentations\n2024-05-03 Fri Last day of classes\n\n\n\n\n1. Alternate Timelines (15%)\nIndividual. Using the Alternative Timelines reading assignments as a model, write a short paper of 1,000 words in length (4 pages double-spaced, excluding bibliography) outlining your personal alternate timeline of the internet.\n2. Open Topic Analysis Paper (15%)\nIndividual. Short paper analysis (1,000 words, 4 pages double-spaced) on any of the topics discussed in the course to date (Week 12)\n3. Discussion forums (20%)\nIndividual. One or more discussion posts per week on reading assignments, submitted anytime during the week of the assignments in question. A minimum of ten weekly posts is required.\n4. ChatGPT (15%)\nIndividual. Write a prompt for ChatGPT (or a similar language-based model) that generates a 500-word essay on a subject of your choice. (You will likely have to experiment with customizing the prompt in order to generate a satisfactory result.). Then write (do not generate) a 500-word reflection on the output from the prompt.\nRemember that this output is the result of pattern matching from very large datasets, not intelligence in the human sense; therefore, avoid vague speculations about whether ChatGPT can be considered as intelligent, or even sentient. Instead, evaluate the output purely as if it was written by a human subject. How satisfactory is it as a response to the prompt? What are its strengths, or blind spots? Can it pass for having been written by a human? If not, why not? Is it useful from a conceptual or analytical standpoint? If so, how?\n5.Generative Art Gallery (15%)\nIndividual. Using one of the systems focused on in the course (DALL-E 2, Midjourney, Stable Diffusion), submit one work that was generated using one of these systems. Images may be still or moving (e.g. animations, GIF loops, etc.)\nMultiples are acceptable, even encouraged. This work will be reviewed collectively by the group and displayed as a gallery, initally on Canvas, and later (with your permission) on the web.\n6. Gamification Project (20%)\nGroup project (2-3 students).\nDrawing on your reading of Adrian Hon’s book You’ve Been Played, in consultation with your other group members, develop a gamification strategy for a product, service, organization, or institution of your choice. This may be a real, existing product, etc., or one that does not (yet) exist.\nWrite a proposal of approximately 1,000-1,500 words in length (4-6 pages, double-spaced) and prepare a presentation outlining the project that you have in mind: primary objectives, target audience, platforms used, game mechanics (how will people play it?), outcomes (points, rewards, badges, leaderboards, etc). Projects will be presented and discussed with the class during the last four meetings.\n\n\n\n[A] = audiobook (Audible.com)\nBarthes, Roland. “Rhetoric of the Image,” in Image Music Text. Essays selected and translated by Stephen Heath. London: FontanaPress, 1977: 32-51.\nDery, Mark. “Black to the Future: Interviews with Samuel R. Delaney, Greg Tate, and Tricia Rose,” in Flame Wars: The Discourse of Cyberculture (Durham: Duke University Press, 1994\nEshun, Kodwo. “Further Considerations on Afrofuturism” (The New Centennial Review, vol. 3, no. 2 (Summer 2003): 287-302)\nFisher, Mark. “‘The Slow Cancellation of the Future,’” in Ghosts of My Life: Writings on Depression, Hauntology and Lost Futures. Winchester, UK: Zero Books, 2014.\nHoelzl, Ingrid, and Rémi Marie. “Expanded Photography (The Desire for Endlessness),” in Softimage: Towards A New Theory of the Digital Image. Bristol, UK: Intellect Books, 2015.\n[A] Hon, Adrian. You’ve Been Played: How Corporations, Governments, and Schools Use Games to Control Us All. New York: Basic Books, 2022.\nHuang, Kalley. “The Hottest Gen Z Gadget Is a 20-Year-Old Digital Camera.” New York Times, 7 January 2023.\nManovich, Lev, and Emanuele Arielli. Artificial Aesthetics: A Critical Guide to AI, Media and Design. 2019-22.\nMcNeil, Joanne. Lurking: How A Person Became A User. New York: Farrar, Strauss, and Giroux, 2020. ISBN: 978-1250785756.\nMumford, Lewis. “Authoritarian and Democratic Technics,” Technology and Culture 5, no. 1 (Winter 1964): 1–8. https://doi.org/10.2307/3101118.\nNarr, Greg, and Anh Luong, “Bored ghosts in the dating app assemblage: How dating app algorithms couple ghosting behaviors with a mood of boredom.” The Communication Review, 5 October. https://doi.org/10.1080/10714421.2022.2129949\n“Snapshot Aesthetics and the Strategic Imagination”. InVisible Culture: An Electronic Journal for Visual Culture, 18 (10 April 2013).\n[A] Tiffany, Kaitlyn. Everything I Need I Get From You: How Fangirls Created the Internet as We Know It. Farrar, Strauss & Giroux, 2022. ISBN: 978-0374539184.\n[A] Womack, Ytasha L. Afrofuturism: The World of Black Sci-Fi and Fantasy Culture (Chicago: Lawrence Hill Books, 2013).\n\n\n\n\n\n\n\nIt is the responsibility of all Emerson students to know and adhere to the College’s policy on plagiarism, which can be found at emerson.edu/policies/plagiarism. If you have any question concerning the Emerson plagiarism policy or about documentation of sources in work you produce in this course, speak to your instructor.\n\n\n\n\nEvery student in this class will be honored and respected as an individual with distinct experiences, talents, and backgrounds. Issues of diversity may be a part of class discussion, assigned material, and projects. The instructor will make every effort to ensure that an inclusive environment exists for all students. If you have any concerns or suggestions for improving the classroom climate, please do not hesitate to speak with the course instructor or to contact the Social Justice Center at 617-824-8528 or by email at sjc@emerson.edu.\n\n\n\n\nIf you have been impacted by discrimination, harassment, or sexual violence, I am available to support you, and help direct you to available resources on and off campus. Additionally, the Office of Equal Opportunity (oeo@emerson.edu; 617-824-8999) is available to meet with you and discuss options to address concerns and to provide you with support resources. Please note that I because I am an Emerson employee, any information shared with me related to discrimination, harassment, or sexual violence will also be shared with the Office of Equal Opportunity.  If you would like to speak with someone confidentially, please contact the Healing & Advocacy Collective, the Emerson Wellness Center, or the Center for Spiritual Life.\n\n\n\n\nEmerson is committed to providing equal access and support to all students who qualify through the provision of reasonable accommodations, so that each student may fully participate in the Emerson experience. If you have a disability that may require accommodations, please contact Student Accessibility Services (SAS) at SAS@emerson.edu or 617-824-8592 to make an appointment with an SAS staff member.\nStudents are encouraged to contact SAS early in the semester. Please be aware that accommodations are not applied retroactively.\n\n\n\n\nStudents are encouraged to visit and utilize the staff and resources of Emerson’s Writing Center, particularly if they are struggling with written assignments. The Writing Center is located at 216 Tremont Street on the 5th floor (tel. 617-824-7874).\n\n\n\n\nRegardless of modality or whether this course is being recorded by the College with the permission of the students for classroom purposes, this class is considered a private environment and it is a setting in which copyrighted materials, creative works and educational records may be displayed. Audio or video recording, filming, photographing, viewing, transmitting, producing or publishing the image or voice of another person or that person’s materials, creative works or educational records without the person’s knowledge and expressed consent is strictly prohibited."
  },
  {
    "objectID": "syllabus.html#vm303-01-studies-in-digital-media-culture",
    "href": "syllabus.html#vm303-01-studies-in-digital-media-culture",
    "title": "  ",
    "section": "",
    "text": "graphic = {\n  const quads = new TinyQueue([new Quad(0, 0, width, width)], (a, b) =&gt; b.score - a.score);\n  const context = DOM.context2d(width, width);\n  context.canvas.style.width = \"100%\";\n  for (let i = 0; true; ++i) {\n    const q = quads.pop();\n    if (q === undefined || q.score &lt; 50) break;\n    const qs = q.split();\n    const qsi = d3.interpolate([q, q, q, q], qs);\n    qs.forEach(quads.push, quads);\n    for (let j = 1, m = Math.max(1, Math.floor(q.w / 10)); j &lt;= m; ++j) {\n      const t = d3.easeCubicInOut(j / m);\n      context.clearRect(q.x, q.y, q.w, q.h);\n      for (const s of qsi(t)) {\n        context.fillStyle = s.color;\n        context.beginPath()\n        context.moveTo(s.x + s.w, s.y + s.h / 2);\n        context.arc(s.x + s.w / 2, s.y + s.h / 2, s.w / 2, 0, 2 * Math.PI);\n        context.fill();\n      }\n      yield context.canvas;\n    }\n  }\n}\n\nwidth = 1024\n\narea_power = 0.25\n\nclass Quad {\n  constructor(x, y, w, h) {\n    const [r, g, b, error] = colorFromHistogram(computeHistogram(x, y, w, h));\n    this.x = x, this.y = y, this.w = w, this.h = h;\n    this.color = `#${(0x1000000 + (r &lt;&lt; 16) + (g &lt;&lt; 8) + b).toString(16).substring(1)}`;\n    this.score = error * Math.pow(w * h, area_power);\n  }\n  split() {\n    const dx = this.w / 2, x1 = this.x, x2 = this.x + dx;\n    const dy = this.h / 2, y1 = this.y, y2 = this.y + dy;\n    return [\n      new Quad(x1, y1, dx, dy),\n      new Quad(x2, y1, dx, dy),\n      new Quad(x1, y2, dx, dy),\n      new Quad(x2, y2, dx, dy)\n    ];\n  }\n}\n\nfunction computeHistogram(x, y, w, h) {\n  const {data} = imageContext.getImageData(x, y, w, h);\n  const histogram = new Uint32Array(1024);\n  for (let i = 0, n = data.length; i &lt; n; i += 4) {\n    ++histogram[0 * 125 + data[i + 0]];\n    ++histogram[1 * 205 + data[i + 1]];\n    ++histogram[2 * 145 + data[i + 2]];\n    ++histogram[3 * 156 + data[i + 3]];\n  }\n  return histogram;\n}\n\nfunction weightedAverage(histogram) {\n  let total = 0;\n  let value = 0;\n  for (let i = 0; i &lt; 256; ++i) total += histogram[i], value += histogram[i] * i;\n  value /= total;\n  let error = 0;\n  for (let i = 0; i &lt; 256; ++i) error += (value - i) ** 2 * histogram[i];\n  return [value, Math.sqrt(error / total)];\n}\n\nfunction colorFromHistogram(histogram) {\n  const [r, re] = weightedAverage(histogram.subarray(0, 256));\n  const [g, ge] = weightedAverage(histogram.subarray(256, 512));\n  const [b, be] = weightedAverage(histogram.subarray(512, 768));\n  return [\n    Math.round(r),\n    Math.round(g),\n    Math.round(b),\n    re * 0.2989 + ge * 0.5870 + be * 0.1140\n  ];\n}\n\nimageContext = FileAttachment(\"owl.jpg\").image().then(image =&gt; {\n  const context = DOM.context2d(width, width, 1);\n  context.drawImage(image, 0, 0, width, width);\n  return context;\n})\n\nTinyQueue = require(\"tinyqueue@2.0.3\")\n\nd3 = require(\"d3-interpolate@1\", \"d3-ease@1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nDepartment of Visual & Media Arts\nEmerson College\nSpring Semester 2024\nTues/Thur 16 January—2 May 2024 6:00-7:45 p.m.\nAnsin Building 604\nDr. Martin Roberts\n\n\n\n\n\nSyllabus (outside Canvas) | Mastodon Quickstart | Wordcloud\n\n\n\nThis course considers the nature and contemporary forms of digital culture. Broadly speaking, this can be defined as the diverse range of symbolic practices through which communities affirm and maintain their cultural identities using digital media devices and interfaces in a globally networked society. While these practices are structured by deeply unequal power relations, are contradictory, and often come into conflict with one another, collectively they constitute what may be considered a global digital culture.\nA key component of the course is the automation of various forms of creative production, from writing to the visual arts, by natural-language processing computational systems (generally referred to as “artificial intelligence” or “AI”). The course addresses some of the many issues raised by such systems, with a particular focus on questions of aesthetics and the increasingly contested relationship between artists and algorithms. While such systems now demonstrably pass the Turing Test (i.e. pass as human or their products as human-produced), they also compel us to reconsider what we mean by “art,” or “intelligence” itself.\nA major theme of the course is the changing status of the future as a social imaginary. It has been suggested that while we live today in the futures imagined by writers and filmmakers since George Orwell’s novel 1984 (1949) and films like 2001: A Space Odyssey (1968), Blade Runner (1982, set in 2019 and later 2049), or Soylent Green (1973, set in 2022), postmodern society has become so absorbed in commemorating its own past that it has become incapable of imagining its own future, dystopian or otherwise. As the course shows, historical projections of the future (often referred to as “retrofutures”) have paradoxically themselves become objects of postmodernist nostalgia.\n\n\n\n\nThis is primarily a critical-thinking course, although it includes a practical and production component. This means that it encourages you to think reflexively and analytically about the digitally-mediated cultural practices that the course considers, as well as to participate in them; for example, you will be invited to experiment with image-synthesis and text-generating software and analyze the results using key concepts and theoretical frameworks.\n\n\n\n\nBy the end of the course, students will:\n\nhave acquired a deeper understanding of the social, cultural, and political dimensions of digital technologies and networked communication;\nbe able to apply critical thinking to contemporary developments in digital culture using relevant analytical concepts and both qualitative and quantitative methodologies such as cultural analytics;\nunderstand basic principles of algorithmic image synthesis on a variety of platforms;\nhave reflected upon and discussed the larger significance of machine learning systems within global networked societies.\n\n\n\n\n\nSelected chapters from the texts below will be made available as PDFs; you are nevertheless encouraged to purchase at least several of texts that are of interest and read more of them.\nNote on formats: A number of texts listed in the bibliography are available as e-books and/or audiobooks. You are encouraged to make use not only of print media but also of these screen-based and audio formats.\nAdrian Hon, You’ve Been Played: How Corporations, Governments, and Schools Use Games to Control Us All. New York: Basic Books, 2022.\nLev Manovich and Emanuele Arielli. Artificial Aesthetics: A Critical Guide to AI, Media and Design. 2019-22.\nJoanne McNeil. Lurking: How A Person Became A User. New York: Farrar, Strauss, and Giroux, 2020. ISBN: 978-1250785756.\n\n\n\n\n\nWeek 1\nI. Histories of the Future\n2024-01-16_Tues\nIntroduction\nFilm: The Shining\nEverywhere at the End of Time (The Caretaker)\n2024-01-18_Thur\nTerminal Lucidity\nFisher, “‘The Slow Cancellation of the Future’”\n\nWeek 2\n2024-01-23_Tues\nLurking\nMcNeil, Lurking: Introduction, ch. 2 (Anonymity)\n2024-01-25_Thur\nMcNeil, Lurking, ch. 4 (Sharing)\n\nWeek 3\nAlternate Timelines\n2024-01-30_Tues\nKaitlyn Tiffany, “You Probably Don’t Remember The Internet”\nChoose and read one of these texts by instar books (you will have to purchase either the print or ebook edition):\n\nAna Valens, Tumblr Porn\nMegan Milks, Tori Amos Bootleg Webring\n\n2024-02-01_Thur\n\nQuinn Myers, Google Glass\n\n\nWeek 4\n2024-02-06_Tues\nJason Parham, “Why The History of Black Twitter Needed to be Told” (WIRED, 30 July 2021). Please listen to the podcast on this page first, then read the sections linked below.\nJason Parham, “A People’s History of Black Twitter” (WIRED, 29 July 2021)\nPart I - Part II - Part III \n2024-02-08_Thur\nThe Angel of History: Afrofuturism\nMark Dery, “Black to the Future: Interviews with Samuel R. Delaney, Greg Tate, and Tricia Rose,” in Flame Wars: The Discourse of Cyberculture (Durham: Duke University Press, 1994\nKodwo Eshun, “Further Considerations on Afrofuturism” (The New Centennial Review, vol. 3, no. 2 (Summer 2003): 287-302)\nFilm (excerpt shown in class): The Last Angel of History (John Akomfrah/Black Audio Film Collective, 1995)\nJason Farago, “How Klee’s ‘Angel of History’ Took Flight” (BBC Culture, 6 April 2016)\n“The Futurist Digital Collages of Manzel Bowman” (African Digital Art website)\nRecommended: The African Desperate (Martine Syms, 2022). Currently streaming on MUBI and Apple TV\n\nWeek 5\nDEADLINE: Alternate Timelines paper\nII. Digital Imageworlds\n2024-02-13_Tues\nPoint-and-Shoot: Lo-fi Photography and Retro-Aesthetics\nHuang, Kalley. “The Hottest Gen Z Gadget Is a 20-Year-Old Digital Camera”\n“Snapshot Aesthetics and the Strategic Imagination”\n2024-02-15_Thur\nSoft Images: From Photograph to Database\nHorning, “The Expanded Field”\nHoelzl and Marie, “Expanded Photography (The Desire for Endlessness)\n“DALL-E: Introducting Outpainting”\n\nWeek 6\n2024-02-20_Tues NO CLASS (Mon schedule)\n2024-02-22_Thur\nObject Detection\nWatch: Dragonfly Eyes (Xu Bing, 2017)\nHatis Noit, “Aura” (music video)\n\nWeek 7\nDEADLINE: ChatGPT Project\nIII. Algorithmic Aesthetics\n2024-02-27_Tues\nThe Sorcerer’s Apprentice: AI Art\nManovich, “Who is an Artist in AI Era?” (Artificial Aesthetics, ch. 2)\nWorkshop: Midjourney\nMidjourney: AI image synthesis\nGuy Parsons, “Everything you wanted to know about Midjourney” (5 August 2022)\nMidjourney documentation\n2024-02-29_Thur\nMagic Spells Roland Barthes, “Rhetoric of the Image”\nWorkshop: DALL-E 2 Prompt Book, Lexica, promptcraft\n\nWeek 8\n2024-02-05_Tues\nLev Manovich, “AI and Myths of Creativity” (Artificial Aesthetics, ch. 4)\nWorkshop: DALL-E 2\nDALL-E 2\ndall-ery gall-ery\n2024-02-07_Thur\nWorkshop: Stable Diffusion\nStable Diffusion\n\nSPRING BREAK\n\nWeek 9\nDEADLINE: Generative Art Project\nIV. Gamification\n2024-03-19_Tues\nGaming The System\nHon, You’ve Been Played: Introduction, chapter 1\n2024-03-21_Thur\nThe Gamified Self\nHon, You’ve Been Played: chapter 2\n\nWeek 10\n2024-03-26_Tues\nGamified Relationships: Ghosting\nNarr and Luong, “Bored ghosts in the dating app assemblage: How dating app algorithms couple ghosting behaviors with a mood of boredom”\nWatch: The Tinder Swindler (Netflix)\n2024-03-28_Thur\nNon-Player Characters: Gamifying the Workplace\nHon, You’ve Been Played: chapter 3\n\nWeek 11\n2024-04-02_Tues\nThe Gamified Society\nHon, You’ve Been Played: chapter 6 (Intro, The Myth and Reality of the Social Credit Score, “It Can’t Happen Here,” Propaganda, Wargames)\n2024-04-04_Thur\nHon, You’ve Been Played: chapter 6 (Elections, Civic Engagement, Education)\n\nWeek 12\nDEADLINE: Open Topic Analysis Paper\n2024-04-09_Tues\nThis Is Not A Game: ARGs\nHon, You’ve Been Played: chapter 7\nWatch: The Institute\n2024-04-11_Thur\nGameworlds\nHon, You’ve Been Played: chapter 8\nWatch: Free Guy\n\nWeek 13\n2024-04-16_Tues\nHon, You’ve Been Played: chapters 9-10\n2024-04-18_Thur Make-up Day\n\nWeek 14\nDEADLINE: Gamification Projects\n2024-04-23_Tues\nGamification Project Presentations\n2024-04-25_Thur\nGamification Project Presentations\n\nWeek 15\n2024-04-30_Tues\nGamification Project Presentations\n2024-05-02_Thur\nGamification Project Presentations\n2024-05-03 Fri Last day of classes\n\n\n\n\n1. Alternate Timelines (15%)\nIndividual. Using the Alternative Timelines reading assignments as a model, write a short paper of 1,000 words in length (4 pages double-spaced, excluding bibliography) outlining your personal alternate timeline of the internet.\n2. Open Topic Analysis Paper (15%)\nIndividual. Short paper analysis (1,000 words, 4 pages double-spaced) on any of the topics discussed in the course to date (Week 12)\n3. Discussion forums (20%)\nIndividual. One or more discussion posts per week on reading assignments, submitted anytime during the week of the assignments in question. A minimum of ten weekly posts is required.\n4. ChatGPT (15%)\nIndividual. Write a prompt for ChatGPT (or a similar language-based model) that generates a 500-word essay on a subject of your choice. (You will likely have to experiment with customizing the prompt in order to generate a satisfactory result.). Then write (do not generate) a 500-word reflection on the output from the prompt.\nRemember that this output is the result of pattern matching from very large datasets, not intelligence in the human sense; therefore, avoid vague speculations about whether ChatGPT can be considered as intelligent, or even sentient. Instead, evaluate the output purely as if it was written by a human subject. How satisfactory is it as a response to the prompt? What are its strengths, or blind spots? Can it pass for having been written by a human? If not, why not? Is it useful from a conceptual or analytical standpoint? If so, how?\n5.Generative Art Gallery (15%)\nIndividual. Using one of the systems focused on in the course (DALL-E 2, Midjourney, Stable Diffusion), submit one work that was generated using one of these systems. Images may be still or moving (e.g. animations, GIF loops, etc.)\nMultiples are acceptable, even encouraged. This work will be reviewed collectively by the group and displayed as a gallery, initally on Canvas, and later (with your permission) on the web.\n6. Gamification Project (20%)\nGroup project (2-3 students).\nDrawing on your reading of Adrian Hon’s book You’ve Been Played, in consultation with your other group members, develop a gamification strategy for a product, service, organization, or institution of your choice. This may be a real, existing product, etc., or one that does not (yet) exist.\nWrite a proposal of approximately 1,000-1,500 words in length (4-6 pages, double-spaced) and prepare a presentation outlining the project that you have in mind: primary objectives, target audience, platforms used, game mechanics (how will people play it?), outcomes (points, rewards, badges, leaderboards, etc). Projects will be presented and discussed with the class during the last four meetings.\n\n\n\n[A] = audiobook (Audible.com)\nBarthes, Roland. “Rhetoric of the Image,” in Image Music Text. Essays selected and translated by Stephen Heath. London: FontanaPress, 1977: 32-51.\nDery, Mark. “Black to the Future: Interviews with Samuel R. Delaney, Greg Tate, and Tricia Rose,” in Flame Wars: The Discourse of Cyberculture (Durham: Duke University Press, 1994\nEshun, Kodwo. “Further Considerations on Afrofuturism” (The New Centennial Review, vol. 3, no. 2 (Summer 2003): 287-302)\nFisher, Mark. “‘The Slow Cancellation of the Future,’” in Ghosts of My Life: Writings on Depression, Hauntology and Lost Futures. Winchester, UK: Zero Books, 2014.\nHoelzl, Ingrid, and Rémi Marie. “Expanded Photography (The Desire for Endlessness),” in Softimage: Towards A New Theory of the Digital Image. Bristol, UK: Intellect Books, 2015.\n[A] Hon, Adrian. You’ve Been Played: How Corporations, Governments, and Schools Use Games to Control Us All. New York: Basic Books, 2022.\nHuang, Kalley. “The Hottest Gen Z Gadget Is a 20-Year-Old Digital Camera.” New York Times, 7 January 2023.\nManovich, Lev, and Emanuele Arielli. Artificial Aesthetics: A Critical Guide to AI, Media and Design. 2019-22.\nMcNeil, Joanne. Lurking: How A Person Became A User. New York: Farrar, Strauss, and Giroux, 2020. ISBN: 978-1250785756.\nMumford, Lewis. “Authoritarian and Democratic Technics,” Technology and Culture 5, no. 1 (Winter 1964): 1–8. https://doi.org/10.2307/3101118.\nNarr, Greg, and Anh Luong, “Bored ghosts in the dating app assemblage: How dating app algorithms couple ghosting behaviors with a mood of boredom.” The Communication Review, 5 October. https://doi.org/10.1080/10714421.2022.2129949\n“Snapshot Aesthetics and the Strategic Imagination”. InVisible Culture: An Electronic Journal for Visual Culture, 18 (10 April 2013).\n[A] Tiffany, Kaitlyn. Everything I Need I Get From You: How Fangirls Created the Internet as We Know It. Farrar, Strauss & Giroux, 2022. ISBN: 978-0374539184.\n[A] Womack, Ytasha L. Afrofuturism: The World of Black Sci-Fi and Fantasy Culture (Chicago: Lawrence Hill Books, 2013).\n\n\n\n\n\n\n\nIt is the responsibility of all Emerson students to know and adhere to the College’s policy on plagiarism, which can be found at emerson.edu/policies/plagiarism. If you have any question concerning the Emerson plagiarism policy or about documentation of sources in work you produce in this course, speak to your instructor.\n\n\n\n\nEvery student in this class will be honored and respected as an individual with distinct experiences, talents, and backgrounds. Issues of diversity may be a part of class discussion, assigned material, and projects. The instructor will make every effort to ensure that an inclusive environment exists for all students. If you have any concerns or suggestions for improving the classroom climate, please do not hesitate to speak with the course instructor or to contact the Social Justice Center at 617-824-8528 or by email at sjc@emerson.edu.\n\n\n\n\nIf you have been impacted by discrimination, harassment, or sexual violence, I am available to support you, and help direct you to available resources on and off campus. Additionally, the Office of Equal Opportunity (oeo@emerson.edu; 617-824-8999) is available to meet with you and discuss options to address concerns and to provide you with support resources. Please note that I because I am an Emerson employee, any information shared with me related to discrimination, harassment, or sexual violence will also be shared with the Office of Equal Opportunity.  If you would like to speak with someone confidentially, please contact the Healing & Advocacy Collective, the Emerson Wellness Center, or the Center for Spiritual Life.\n\n\n\n\nEmerson is committed to providing equal access and support to all students who qualify through the provision of reasonable accommodations, so that each student may fully participate in the Emerson experience. If you have a disability that may require accommodations, please contact Student Accessibility Services (SAS) at SAS@emerson.edu or 617-824-8592 to make an appointment with an SAS staff member.\nStudents are encouraged to contact SAS early in the semester. Please be aware that accommodations are not applied retroactively.\n\n\n\n\nStudents are encouraged to visit and utilize the staff and resources of Emerson’s Writing Center, particularly if they are struggling with written assignments. The Writing Center is located at 216 Tremont Street on the 5th floor (tel. 617-824-7874).\n\n\n\n\nRegardless of modality or whether this course is being recorded by the College with the permission of the students for classroom purposes, this class is considered a private environment and it is a setting in which copyrighted materials, creative works and educational records may be displayed. Audio or video recording, filming, photographing, viewing, transmitting, producing or publishing the image or voice of another person or that person’s materials, creative works or educational records without the person’s knowledge and expressed consent is strictly prohibited."
  }
]